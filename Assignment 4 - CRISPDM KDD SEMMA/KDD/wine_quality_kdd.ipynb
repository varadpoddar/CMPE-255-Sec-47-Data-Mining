{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 — KDD Case Study (Wine Quality Regression)\n",
    "\n",
    "Dataset: [`codesignal/wine-quality`](https://huggingface.co/datasets/codesignal/wine-quality) — red split (1,599 rows, 11 numeric features, target: quality 0–10).\n",
    "\n",
    "Goal: Predict wine `quality` using KDD stages: Selection → Preprocessing → Transformation → Data Mining → Evaluation/Interpretation.\n",
    "\n",
    "Environment: Python 3.11 (`.venv`), scikit-learn, pandas, seaborn, SHAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import shap\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "FIG_DIR = Path(\"figures\")\n",
    "FIG_DIR.mkdir(exist_ok=True)\n",
    "RNG = 42\n",
    "pd.set_option(\"display.max_columns\", 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection\n",
    "- Load red wine split; target = `quality` (ordinal/treated as regression).\n",
    "- Rationale: small, clean numeric dataset suitable for transformation (scaling/PCA) and regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"codesignal/wine-quality\", split=\"red\")\n",
    "df = ds.to_pandas()\n",
    "df.shape, df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"quality\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RNG)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target distribution and correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(y, bins=10, kde=True)\n",
    "plt.title(\"Quality distribution (red wine)\")\n",
    "plt.tight_layout()\n",
    "target_fig = FIG_DIR / \"target_distribution.png\"\n",
    "plt.savefig(target_fig)\n",
    "target_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(df.corr(), annot=False, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Feature correlation matrix\")\n",
    "plt.tight_layout()\n",
    "corr_fig = FIG_DIR / \"correlation_matrix.png\"\n",
    "plt.savefig(corr_fig)\n",
    "corr_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "- Check missingness and descriptive stats.\n",
    "- All numeric features → scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df.isna().sum().sum()\n",
    "df.describe(), missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation\n",
    "- Standardize features.\n",
    "- PCA (variance explained) to inspect structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "pca = PCA(n_components=6, random_state=RNG)\n",
    "pca.fit(X_scaled)\n",
    "explained = np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(range(1, len(explained)+1), explained, marker='o')\n",
    "plt.xlabel('Components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.title('PCA variance (standardized)')\n",
    "plt.tight_layout()\n",
    "pca_fig = FIG_DIR / \"pca_variance.png\"\n",
    "plt.savefig(pca_fig)\n",
    "pca_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining\n",
    "- Pipelines: scale → model.\n",
    "- Models: Dummy, RandomForest, GradientBoosting.\n",
    "- Tuning: RandomizedSearchCV on GradientBoosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Pipeline([(\"scaler\", StandardScaler())])\n",
    "\n",
    "def eval_reg(model, name: str):\n",
    "    pipe = Pipeline([(\"prep\", preprocessor), (\"model\", model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    return {\"name\": name, \"rmse\": rmse, \"mae\": mae, \"r2\": r2, \"pipeline\": pipe}\n",
    "\n",
    "results = []\n",
    "results.append(eval_reg(DummyRegressor(strategy=\"median\"), \"Dummy\"))\n",
    "results.append(eval_reg(RandomForestRegressor(n_estimators=300, random_state=RNG, n_jobs=-1), \"RandomForest\"))\n",
    "results.append(eval_reg(GradientBoostingRegressor(random_state=RNG), \"GradientBoosting\"))\n",
    "\n",
    "pd.DataFrame([{k:v for k,v in r.items() if k!=\"pipeline\"} for r in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick best and tune GradientBoosting\n",
    "best = sorted(results, key=lambda d: d[\"rmse\"])[0]\n",
    "best_name = best[\"name\"]\n",
    "param_dist = {\n",
    "    \"model__n_estimators\": [200, 300, 400],\n",
    "    \"model__learning_rate\": [0.05, 0.075, 0.1],\n",
    "    \"model__max_depth\": [2, 3, 4],\n",
    "}\n",
    "search = RandomizedSearchCV(\n",
    "    Pipeline([(\"prep\", preprocessor), (\"model\", GradientBoostingRegressor(random_state=RNG))]),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=8,\n",
    "    cv=3,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    random_state=RNG,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "search.fit(X_train, y_train)\n",
    "{'best_params': search.best_params_, 'best_cv_rmse': -search.best_score_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit tuned model and evaluate\n",
    "tuned = search.best_estimator_\n",
    "tuned.fit(X_train, y_train)\n",
    "preds = tuned.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "r2 = r2_score(y_test, preds)\n",
    "{\"rmse\": rmse, \"mae\": mae, \"r2\": r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis\n",
    "residuals = y_test - preds\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.scatterplot(x=preds, y=residuals, alpha=0.4)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Residual')\n",
    "plt.title('Residuals vs Predicted (tuned GB)')\n",
    "plt.tight_layout()\n",
    "resid_fig = FIG_DIR / \"residuals_vs_pred.png\"\n",
    "plt.savefig(resid_fig)\n",
    "resid_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(residuals, bins=30, kde=True)\n",
    "plt.title('Residual distribution (tuned GB)')\n",
    "plt.tight_layout()\n",
    "resid_hist_fig = FIG_DIR / \"residual_hist.png\"\n",
    "plt.savefig(resid_hist_fig)\n",
    "resid_hist_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP summary (sampled)\n",
    "X_sample = X_test.sample(n=min(400, len(X_test)), random_state=RNG)\n",
    "X_proc = tuned.named_steps[\"prep\"].transform(X_sample)\n",
    "feature_names = tuned.named_steps[\"prep\"].get_feature_names_out()\n",
    "explainer = shap.Explainer(tuned.named_steps[\"model\"], X_proc, feature_names=feature_names)\n",
    "shap_values = explainer(X_proc, check_additivity=False)\n",
    "shap.plots.beeswarm(shap_values, max_display=12, show=False)\n",
    "plt.tight_layout()\n",
    "shap_fig = FIG_DIR / \"shap_beeswarm.png\"\n",
    "plt.savefig(shap_fig, bbox_inches=\"tight\")\n",
    "shap_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation & Interpretation\n",
    "- Tuned GB is best; compare RMSE/MAE/R² vs baselines.\n",
    "- Residuals mostly centered, slight skew; monitor high-error cases.\n",
    "- SHAP: key drivers include alcohol, sulphates, volatile acidity, density.\n",
    "- PCA shows ~80% variance captured by first ~5 components."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
