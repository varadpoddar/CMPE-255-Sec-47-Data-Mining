{"cells": [{"cell_type": "markdown", "id": "aab8f537", "metadata": {}, "source": ["# PyCaret Binary Classification \u2014 Adult Income\n", "\n", "Dataset: `adult.csv` (Kaggle). Target: `income` (>50K vs <=50K)."]}, {"cell_type": "markdown", "id": "708c8070", "metadata": {}, "source": ["## Environment\n", "Using Python 3.11 with `pycaret==3.3.0` inside the shared `.venv`. Notebook assumes data CSVs are present in `../data/` and GPU is available; if not, PyCaret will fall back to CPU."]}, {"cell_type": "code", "execution_count": 1, "id": "2680f819", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["   age workclass  fnlwgt     education  education.num marital.status  \\\n", "0   90         ?   77053       HS-grad              9        Widowed   \n", "1   82   Private  132870       HS-grad              9        Widowed   \n", "2   66         ?  186061  Some-college             10        Widowed   \n", "3   54   Private  140359       7th-8th              4       Divorced   \n", "4   41   Private  264663  Some-college             10      Separated   \n", "\n", "          occupation   relationship   race     sex  capital.gain  \\\n", "0                  ?  Not-in-family  White  Female             0   \n", "1    Exec-managerial  Not-in-family  White  Female             0   \n", "2                  ?      Unmarried  Black  Female             0   \n", "3  Machine-op-inspct      Unmarried  White  Female             0   \n", "4     Prof-specialty      Own-child  White  Female             0   \n", "\n", "   capital.loss  hours.per.week native.country income  \n", "0          4356              40  United-States  <=50K  \n", "1          4356              18  United-States  <=50K  \n", "2          4356              40  United-States  <=50K  \n", "3          3900              40  United-States  <=50K  \n", "4          3900              40  United-States  <=50K  \n", "income\n", "<=50K    24720\n", ">50K      7841\n", "Name: count, dtype: int64\n"]}], "source": ["import pandas as pd\n", "from pycaret.classification import *\n", "\n", "csv_path = \"../data/adult.csv\"\n", "df = pd.read_csv(csv_path)\n", "print(df.head())\n", "print(df['income'].value_counts())"]}, {"cell_type": "code", "execution_count": 2, "id": "37aa0b66", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n", "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n", "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n", "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n", "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n"]}, {"name": "stderr", "output_type": "stream", "text": ["[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n", "Please recompile with CMake option -DUSE_GPU=1\n", "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n", "Please recompile with CMake option -DUSE_CUDA=1\n"]}, {"name": "stdout", "output_type": "stream", "text": ["[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n", "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n", "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n", "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n", "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n", "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n", "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n", "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n", "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n", "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n", "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n", "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n", "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n", "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n", "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n", "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n", "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n", "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n", "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n", "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n"]}, {"name": "stderr", "output_type": "stream", "text": ["[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n", "Please recompile with CMake option -DUSE_GPU=1\n", "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n", "Please recompile with CMake option -DUSE_CUDA=1\n", "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n", "Please recompile with CMake option -DUSE_GPU=1\n", "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n", "Please recompile with CMake option -DUSE_CUDA=1\n", "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n", "Please recompile with CMake option -DUSE_GPU=1\n", "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n", "Please recompile with CMake option -DUSE_CUDA=1\n", "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n", "Please recompile with CMake option -DUSE_GPU=1\n", "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n", "Please recompile with CMake option -DUSE_CUDA=1\n"]}, {"name": "stdout", "output_type": "stream", "text": ["[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n", "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n", "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n", "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n", "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n"]}, {"name": "stderr", "output_type": "stream", "text": ["[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n", "Please recompile with CMake option -DUSE_GPU=1\n", "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n", "Please recompile with CMake option -DUSE_CUDA=1\n"]}, {"data": {"text/html": ["<style type=\"text/css\">\n", "#T_d5969_row10_col1, #T_d5969_row16_col1, #T_d5969_row18_col1, #T_d5969_row23_col1 {\n", "  background-color: lightgreen;\n", "}\n", "</style>\n", "<table id=\"T_d5969\">\n", "  <thead>\n", "    <tr>\n", "      <th class=\"blank level0\" >&nbsp;</th>\n", "      <th id=\"T_d5969_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n", "      <th id=\"T_d5969_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n", "      <td id=\"T_d5969_row0_col0\" class=\"data row0 col0\" >Session id</td>\n", "      <td id=\"T_d5969_row0_col1\" class=\"data row0 col1\" >42</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n", "      <td id=\"T_d5969_row1_col0\" class=\"data row1 col0\" >Target</td>\n", "      <td id=\"T_d5969_row1_col1\" class=\"data row1 col1\" >income</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n", "      <td id=\"T_d5969_row2_col0\" class=\"data row2 col0\" >Target type</td>\n", "      <td id=\"T_d5969_row2_col1\" class=\"data row2 col1\" >Binary</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n", "      <td id=\"T_d5969_row3_col0\" class=\"data row3 col0\" >Target mapping</td>\n", "      <td id=\"T_d5969_row3_col1\" class=\"data row3 col1\" ><=50K: 0, >50K: 1</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n", "      <td id=\"T_d5969_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n", "      <td id=\"T_d5969_row4_col1\" class=\"data row4 col1\" >(32561, 15)</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n", "      <td id=\"T_d5969_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n", "      <td id=\"T_d5969_row5_col1\" class=\"data row5 col1\" >(46063, 67)</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n", "      <td id=\"T_d5969_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n", "      <td id=\"T_d5969_row6_col1\" class=\"data row6 col1\" >(39550, 67)</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n", "      <td id=\"T_d5969_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n", "      <td id=\"T_d5969_row7_col1\" class=\"data row7 col1\" >(6513, 67)</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n", "      <td id=\"T_d5969_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n", "      <td id=\"T_d5969_row8_col1\" class=\"data row8 col1\" >6</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n", "      <td id=\"T_d5969_row9_col0\" class=\"data row9 col0\" >Categorical features</td>\n", "      <td id=\"T_d5969_row9_col1\" class=\"data row9 col1\" >8</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n", "      <td id=\"T_d5969_row10_col0\" class=\"data row10 col0\" >Preprocess</td>\n", "      <td id=\"T_d5969_row10_col1\" class=\"data row10 col1\" >True</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n", "      <td id=\"T_d5969_row11_col0\" class=\"data row11 col0\" >Imputation type</td>\n", "      <td id=\"T_d5969_row11_col1\" class=\"data row11 col1\" >simple</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n", "      <td id=\"T_d5969_row12_col0\" class=\"data row12 col0\" >Numeric imputation</td>\n", "      <td id=\"T_d5969_row12_col1\" class=\"data row12 col1\" >mean</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n", "      <td id=\"T_d5969_row13_col0\" class=\"data row13 col0\" >Categorical imputation</td>\n", "      <td id=\"T_d5969_row13_col1\" class=\"data row13 col1\" >mode</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n", "      <td id=\"T_d5969_row14_col0\" class=\"data row14 col0\" >Maximum one-hot encoding</td>\n", "      <td id=\"T_d5969_row14_col1\" class=\"data row14 col1\" >25</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n", "      <td id=\"T_d5969_row15_col0\" class=\"data row15 col0\" >Encoding method</td>\n", "      <td id=\"T_d5969_row15_col1\" class=\"data row15 col1\" >None</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n", "      <td id=\"T_d5969_row16_col0\" class=\"data row16 col0\" >Fix imbalance</td>\n", "      <td id=\"T_d5969_row16_col1\" class=\"data row16 col1\" >True</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n", "      <td id=\"T_d5969_row17_col0\" class=\"data row17 col0\" >Fix imbalance method</td>\n", "      <td id=\"T_d5969_row17_col1\" class=\"data row17 col1\" >SMOTE</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n", "      <td id=\"T_d5969_row18_col0\" class=\"data row18 col0\" >Normalize</td>\n", "      <td id=\"T_d5969_row18_col1\" class=\"data row18 col1\" >True</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n", "      <td id=\"T_d5969_row19_col0\" class=\"data row19 col0\" >Normalize method</td>\n", "      <td id=\"T_d5969_row19_col1\" class=\"data row19 col1\" >zscore</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n", "      <td id=\"T_d5969_row20_col0\" class=\"data row20 col0\" >Fold Generator</td>\n", "      <td id=\"T_d5969_row20_col1\" class=\"data row20 col1\" >StratifiedKFold</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n", "      <td id=\"T_d5969_row21_col0\" class=\"data row21 col0\" >Fold Number</td>\n", "      <td id=\"T_d5969_row21_col1\" class=\"data row21 col1\" >5</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n", "      <td id=\"T_d5969_row22_col0\" class=\"data row22 col0\" >CPU Jobs</td>\n", "      <td id=\"T_d5969_row22_col1\" class=\"data row22 col1\" >-1</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n", "      <td id=\"T_d5969_row23_col0\" class=\"data row23 col0\" >Use GPU</td>\n", "      <td id=\"T_d5969_row23_col1\" class=\"data row23 col1\" >True</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n", "      <td id=\"T_d5969_row24_col0\" class=\"data row24 col0\" >Log Experiment</td>\n", "      <td id=\"T_d5969_row24_col1\" class=\"data row24 col1\" >MlflowLogger</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n", "      <td id=\"T_d5969_row25_col0\" class=\"data row25 col0\" >Experiment Name</td>\n", "      <td id=\"T_d5969_row25_col1\" class=\"data row25 col1\" >pycaret_binary_adult</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_d5969_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n", "      <td id=\"T_d5969_row26_col0\" class=\"data row26 col0\" >USI</td>\n", "      <td id=\"T_d5969_row26_col1\" class=\"data row26 col1\" >d025</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n"], "text/plain": ["<pandas.io.formats.style.Styler at 0x140e3e790>"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stderr", "output_type": "stream", "text": ["[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n", "Please recompile with CMake option -DUSE_GPU=1\n", "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n", "Please recompile with CMake option -DUSE_CUDA=1\n", "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n", "Please recompile with CMake option -DUSE_GPU=1\n", "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n", "Please recompile with CMake option -DUSE_CUDA=1\n", "2025/12/09 02:39:32 INFO mlflow.tracking.fluent: Experiment with name 'pycaret_binary_adult' does not exist. Creating a new experiment.\n"]}, {"name": "stdout", "output_type": "stream", "text": ["[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n", "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n", "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n", "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n", "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n", "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n", "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n", "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n", "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n", "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n"]}, {"data": {"text/html": [], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": ["<style type=\"text/css\">\n", "#T_fe1ea th {\n", "  text-align: left;\n", "}\n", "#T_fe1ea_row0_col0, #T_fe1ea_row1_col0, #T_fe1ea_row1_col1, #T_fe1ea_row1_col3, #T_fe1ea_row1_col4, #T_fe1ea_row1_col5, #T_fe1ea_row1_col6, #T_fe1ea_row1_col7, #T_fe1ea_row2_col0, #T_fe1ea_row2_col1, #T_fe1ea_row2_col3, #T_fe1ea_row2_col4, #T_fe1ea_row2_col5, #T_fe1ea_row2_col6, #T_fe1ea_row2_col7, #T_fe1ea_row3_col0, #T_fe1ea_row3_col1, #T_fe1ea_row3_col3, #T_fe1ea_row3_col4, #T_fe1ea_row3_col5, #T_fe1ea_row3_col6, #T_fe1ea_row3_col7, #T_fe1ea_row4_col0, #T_fe1ea_row4_col1, #T_fe1ea_row4_col3, #T_fe1ea_row4_col4, #T_fe1ea_row4_col5, #T_fe1ea_row4_col6, #T_fe1ea_row4_col7, #T_fe1ea_row5_col0, #T_fe1ea_row5_col1, #T_fe1ea_row5_col3, #T_fe1ea_row5_col4, #T_fe1ea_row5_col5, #T_fe1ea_row5_col6, #T_fe1ea_row5_col7, #T_fe1ea_row6_col0, #T_fe1ea_row6_col1, #T_fe1ea_row6_col3, #T_fe1ea_row6_col4, #T_fe1ea_row6_col5, #T_fe1ea_row6_col6, #T_fe1ea_row6_col7, #T_fe1ea_row7_col0, #T_fe1ea_row7_col1, #T_fe1ea_row7_col3, #T_fe1ea_row7_col4, #T_fe1ea_row7_col5, #T_fe1ea_row7_col6, #T_fe1ea_row7_col7, #T_fe1ea_row8_col0, #T_fe1ea_row8_col1, #T_fe1ea_row8_col3, #T_fe1ea_row8_col4, #T_fe1ea_row8_col5, #T_fe1ea_row8_col6, #T_fe1ea_row8_col7, #T_fe1ea_row9_col0, #T_fe1ea_row9_col1, #T_fe1ea_row9_col3, #T_fe1ea_row9_col4, #T_fe1ea_row9_col5, #T_fe1ea_row9_col6, #T_fe1ea_row9_col7, #T_fe1ea_row10_col0, #T_fe1ea_row10_col1, #T_fe1ea_row10_col3, #T_fe1ea_row10_col4, #T_fe1ea_row10_col5, #T_fe1ea_row10_col6, #T_fe1ea_row10_col7, #T_fe1ea_row11_col0, #T_fe1ea_row11_col1, #T_fe1ea_row11_col3, #T_fe1ea_row11_col4, #T_fe1ea_row11_col5, #T_fe1ea_row11_col6, #T_fe1ea_row11_col7, #T_fe1ea_row12_col0, #T_fe1ea_row12_col1, #T_fe1ea_row12_col3, #T_fe1ea_row12_col4, #T_fe1ea_row12_col5, #T_fe1ea_row12_col6, #T_fe1ea_row12_col7, #T_fe1ea_row13_col0, #T_fe1ea_row13_col1, #T_fe1ea_row13_col3, #T_fe1ea_row13_col4, #T_fe1ea_row13_col5, #T_fe1ea_row13_col6, #T_fe1ea_row13_col7 {\n", "  text-align: left;\n", "}\n", "#T_fe1ea_row0_col1, #T_fe1ea_row0_col2, #T_fe1ea_row0_col3, #T_fe1ea_row0_col4, #T_fe1ea_row0_col5, #T_fe1ea_row0_col6, #T_fe1ea_row0_col7, #T_fe1ea_row1_col2, #T_fe1ea_row2_col2, #T_fe1ea_row3_col2, #T_fe1ea_row4_col2, #T_fe1ea_row5_col2, #T_fe1ea_row6_col2, #T_fe1ea_row7_col2, #T_fe1ea_row8_col2, #T_fe1ea_row9_col2, #T_fe1ea_row10_col2, #T_fe1ea_row11_col2, #T_fe1ea_row12_col2, #T_fe1ea_row13_col2 {\n", "  text-align: left;\n", "  background-color: yellow;\n", "}\n", "#T_fe1ea_row0_col8, #T_fe1ea_row1_col8, #T_fe1ea_row2_col8, #T_fe1ea_row3_col8, #T_fe1ea_row4_col8, #T_fe1ea_row5_col8, #T_fe1ea_row6_col8, #T_fe1ea_row7_col8, #T_fe1ea_row8_col8, #T_fe1ea_row9_col8, #T_fe1ea_row10_col8, #T_fe1ea_row12_col8, #T_fe1ea_row13_col8 {\n", "  text-align: left;\n", "  background-color: lightgrey;\n", "}\n", "#T_fe1ea_row11_col8 {\n", "  text-align: left;\n", "  background-color: yellow;\n", "  background-color: lightgrey;\n", "}\n", "</style>\n", "<table id=\"T_fe1ea\">\n", "  <thead>\n", "    <tr>\n", "      <th class=\"blank level0\" >&nbsp;</th>\n", "      <th id=\"T_fe1ea_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n", "      <th id=\"T_fe1ea_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n", "      <th id=\"T_fe1ea_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n", "      <th id=\"T_fe1ea_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n", "      <th id=\"T_fe1ea_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n", "      <th id=\"T_fe1ea_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n", "      <th id=\"T_fe1ea_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n", "      <th id=\"T_fe1ea_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n", "      <th id=\"T_fe1ea_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th id=\"T_fe1ea_level0_row0\" class=\"row_heading level0 row0\" >lightgbm</th>\n", "      <td id=\"T_fe1ea_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n", "      <td id=\"T_fe1ea_row0_col1\" class=\"data row0 col1\" >0.8717</td>\n", "      <td id=\"T_fe1ea_row0_col2\" class=\"data row0 col2\" >0.0000</td>\n", "      <td id=\"T_fe1ea_row0_col3\" class=\"data row0 col3\" >0.8717</td>\n", "      <td id=\"T_fe1ea_row0_col4\" class=\"data row0 col4\" >0.8679</td>\n", "      <td id=\"T_fe1ea_row0_col5\" class=\"data row0 col5\" >0.8689</td>\n", "      <td id=\"T_fe1ea_row0_col6\" class=\"data row0 col6\" >0.6344</td>\n", "      <td id=\"T_fe1ea_row0_col7\" class=\"data row0 col7\" >0.6366</td>\n", "      <td id=\"T_fe1ea_row0_col8\" class=\"data row0 col8\" >3.5860</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_fe1ea_level0_row1\" class=\"row_heading level0 row1\" >gbc</th>\n", "      <td id=\"T_fe1ea_row1_col0\" class=\"data row1 col0\" >Gradient Boosting Classifier</td>\n", "      <td id=\"T_fe1ea_row1_col1\" class=\"data row1 col1\" >0.8606</td>\n", "      <td id=\"T_fe1ea_row1_col2\" class=\"data row1 col2\" >0.0000</td>\n", "      <td id=\"T_fe1ea_row1_col3\" class=\"data row1 col3\" >0.8606</td>\n", "      <td id=\"T_fe1ea_row1_col4\" class=\"data row1 col4\" >0.8580</td>\n", "      <td id=\"T_fe1ea_row1_col5\" class=\"data row1 col5\" >0.8590</td>\n", "      <td id=\"T_fe1ea_row1_col6\" class=\"data row1 col6\" >0.6102</td>\n", "      <td id=\"T_fe1ea_row1_col7\" class=\"data row1 col7\" >0.6109</td>\n", "      <td id=\"T_fe1ea_row1_col8\" class=\"data row1 col8\" >8.2680</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_fe1ea_level0_row2\" class=\"row_heading level0 row2\" >ada</th>\n", "      <td id=\"T_fe1ea_row2_col0\" class=\"data row2 col0\" >Ada Boost Classifier</td>\n", "      <td id=\"T_fe1ea_row2_col1\" class=\"data row2 col1\" >0.8528</td>\n", "      <td id=\"T_fe1ea_row2_col2\" class=\"data row2 col2\" >0.0000</td>\n", "      <td id=\"T_fe1ea_row2_col3\" class=\"data row2 col3\" >0.8528</td>\n", "      <td id=\"T_fe1ea_row2_col4\" class=\"data row2 col4\" >0.8524</td>\n", "      <td id=\"T_fe1ea_row2_col5\" class=\"data row2 col5\" >0.8526</td>\n", "      <td id=\"T_fe1ea_row2_col6\" class=\"data row2 col6\" >0.5961</td>\n", "      <td id=\"T_fe1ea_row2_col7\" class=\"data row2 col7\" >0.5962</td>\n", "      <td id=\"T_fe1ea_row2_col8\" class=\"data row2 col8\" >2.2900</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_fe1ea_level0_row3\" class=\"row_heading level0 row3\" >rf</th>\n", "      <td id=\"T_fe1ea_row3_col0\" class=\"data row3 col0\" >Random Forest Classifier</td>\n", "      <td id=\"T_fe1ea_row3_col1\" class=\"data row3 col1\" >0.8513</td>\n", "      <td id=\"T_fe1ea_row3_col2\" class=\"data row3 col2\" >0.0000</td>\n", "      <td id=\"T_fe1ea_row3_col3\" class=\"data row3 col3\" >0.8513</td>\n", "      <td id=\"T_fe1ea_row3_col4\" class=\"data row3 col4\" >0.8468</td>\n", "      <td id=\"T_fe1ea_row3_col5\" class=\"data row3 col5\" >0.8483</td>\n", "      <td id=\"T_fe1ea_row3_col6\" class=\"data row3 col6\" >0.5776</td>\n", "      <td id=\"T_fe1ea_row3_col7\" class=\"data row3 col7\" >0.5793</td>\n", "      <td id=\"T_fe1ea_row3_col8\" class=\"data row3 col8\" >1.6440</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_fe1ea_level0_row4\" class=\"row_heading level0 row4\" >et</th>\n", "      <td id=\"T_fe1ea_row4_col0\" class=\"data row4 col0\" >Extra Trees Classifier</td>\n", "      <td id=\"T_fe1ea_row4_col1\" class=\"data row4 col1\" >0.8350</td>\n", "      <td id=\"T_fe1ea_row4_col2\" class=\"data row4 col2\" >0.0000</td>\n", "      <td id=\"T_fe1ea_row4_col3\" class=\"data row4 col3\" >0.8350</td>\n", "      <td id=\"T_fe1ea_row4_col4\" class=\"data row4 col4\" >0.8314</td>\n", "      <td id=\"T_fe1ea_row4_col5\" class=\"data row4 col5\" >0.8328</td>\n", "      <td id=\"T_fe1ea_row4_col6\" class=\"data row4 col6\" >0.5372</td>\n", "      <td id=\"T_fe1ea_row4_col7\" class=\"data row4 col7\" >0.5380</td>\n", "      <td id=\"T_fe1ea_row4_col8\" class=\"data row4 col8\" >1.6360</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_fe1ea_level0_row5\" class=\"row_heading level0 row5\" >lr</th>\n", "      <td id=\"T_fe1ea_row5_col0\" class=\"data row5 col0\" >Logistic Regression</td>\n", "      <td id=\"T_fe1ea_row5_col1\" class=\"data row5 col1\" >0.8140</td>\n", "      <td id=\"T_fe1ea_row5_col2\" class=\"data row5 col2\" >0.0000</td>\n", "      <td id=\"T_fe1ea_row5_col3\" class=\"data row5 col3\" >0.8140</td>\n", "      <td id=\"T_fe1ea_row5_col4\" class=\"data row5 col4\" >0.8537</td>\n", "      <td id=\"T_fe1ea_row5_col5\" class=\"data row5 col5\" >0.8240</td>\n", "      <td id=\"T_fe1ea_row5_col6\" class=\"data row5 col6\" >0.5596</td>\n", "      <td id=\"T_fe1ea_row5_col7\" class=\"data row5 col7\" >0.5794</td>\n", "      <td id=\"T_fe1ea_row5_col8\" class=\"data row5 col8\" >1.6740</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_fe1ea_level0_row6\" class=\"row_heading level0 row6\" >dt</th>\n", "      <td id=\"T_fe1ea_row6_col0\" class=\"data row6 col0\" >Decision Tree Classifier</td>\n", "      <td id=\"T_fe1ea_row6_col1\" class=\"data row6 col1\" >0.8050</td>\n", "      <td id=\"T_fe1ea_row6_col2\" class=\"data row6 col2\" >0.0000</td>\n", "      <td id=\"T_fe1ea_row6_col3\" class=\"data row6 col3\" >0.8050</td>\n", "      <td id=\"T_fe1ea_row6_col4\" class=\"data row6 col4\" >0.8076</td>\n", "      <td id=\"T_fe1ea_row6_col5\" class=\"data row6 col5\" >0.8062</td>\n", "      <td id=\"T_fe1ea_row6_col6\" class=\"data row6 col6\" >0.4736</td>\n", "      <td id=\"T_fe1ea_row6_col7\" class=\"data row6 col7\" >0.4737</td>\n", "      <td id=\"T_fe1ea_row6_col8\" class=\"data row6 col8\" >0.7920</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_fe1ea_level0_row7\" class=\"row_heading level0 row7\" >knn</th>\n", "      <td id=\"T_fe1ea_row7_col0\" class=\"data row7 col0\" >K Neighbors Classifier</td>\n", "      <td id=\"T_fe1ea_row7_col1\" class=\"data row7 col1\" >0.8029</td>\n", "      <td id=\"T_fe1ea_row7_col2\" class=\"data row7 col2\" >0.0000</td>\n", "      <td id=\"T_fe1ea_row7_col3\" class=\"data row7 col3\" >0.8029</td>\n", "      <td id=\"T_fe1ea_row7_col4\" class=\"data row7 col4\" >0.8148</td>\n", "      <td id=\"T_fe1ea_row7_col5\" class=\"data row7 col5\" >0.8075</td>\n", "      <td id=\"T_fe1ea_row7_col6\" class=\"data row7 col6\" >0.4884</td>\n", "      <td id=\"T_fe1ea_row7_col7\" class=\"data row7 col7\" >0.4909</td>\n", "      <td id=\"T_fe1ea_row7_col8\" class=\"data row7 col8\" >1.2640</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_fe1ea_level0_row8\" class=\"row_heading level0 row8\" >svm</th>\n", "      <td id=\"T_fe1ea_row8_col0\" class=\"data row8 col0\" >SVM - Linear Kernel</td>\n", "      <td id=\"T_fe1ea_row8_col1\" class=\"data row8 col1\" >0.8010</td>\n", "      <td id=\"T_fe1ea_row8_col2\" class=\"data row8 col2\" >0.0000</td>\n", "      <td id=\"T_fe1ea_row8_col3\" class=\"data row8 col3\" >0.8010</td>\n", "      <td id=\"T_fe1ea_row8_col4\" class=\"data row8 col4\" >0.8474</td>\n", "      <td id=\"T_fe1ea_row8_col5\" class=\"data row8 col5\" >0.8124</td>\n", "      <td id=\"T_fe1ea_row8_col6\" class=\"data row8 col6\" >0.5358</td>\n", "      <td id=\"T_fe1ea_row8_col7\" class=\"data row8 col7\" >0.5587</td>\n", "      <td id=\"T_fe1ea_row8_col8\" class=\"data row8 col8\" >1.2300</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_fe1ea_level0_row9\" class=\"row_heading level0 row9\" >ridge</th>\n", "      <td id=\"T_fe1ea_row9_col0\" class=\"data row9 col0\" >Ridge Classifier</td>\n", "      <td id=\"T_fe1ea_row9_col1\" class=\"data row9 col1\" >0.7860</td>\n", "      <td id=\"T_fe1ea_row9_col2\" class=\"data row9 col2\" >0.0000</td>\n", "      <td id=\"T_fe1ea_row9_col3\" class=\"data row9 col3\" >0.7860</td>\n", "      <td id=\"T_fe1ea_row9_col4\" class=\"data row9 col4\" >0.8439</td>\n", "      <td id=\"T_fe1ea_row9_col5\" class=\"data row9 col5\" >0.7993</td>\n", "      <td id=\"T_fe1ea_row9_col6\" class=\"data row9 col6\" >0.5131</td>\n", "      <td id=\"T_fe1ea_row9_col7\" class=\"data row9 col7\" >0.5423</td>\n", "      <td id=\"T_fe1ea_row9_col8\" class=\"data row9 col8\" >0.8720</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_fe1ea_level0_row10\" class=\"row_heading level0 row10\" >lda</th>\n", "      <td id=\"T_fe1ea_row10_col0\" class=\"data row10 col0\" >Linear Discriminant Analysis</td>\n", "      <td id=\"T_fe1ea_row10_col1\" class=\"data row10 col1\" >0.7860</td>\n", "      <td id=\"T_fe1ea_row10_col2\" class=\"data row10 col2\" >0.0000</td>\n", "      <td id=\"T_fe1ea_row10_col3\" class=\"data row10 col3\" >0.7860</td>\n", "      <td id=\"T_fe1ea_row10_col4\" class=\"data row10 col4\" >0.8439</td>\n", "      <td id=\"T_fe1ea_row10_col5\" class=\"data row10 col5\" >0.7993</td>\n", "      <td id=\"T_fe1ea_row10_col6\" class=\"data row10 col6\" >0.5131</td>\n", "      <td id=\"T_fe1ea_row10_col7\" class=\"data row10 col7\" >0.5423</td>\n", "      <td id=\"T_fe1ea_row10_col8\" class=\"data row10 col8\" >2.8620</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_fe1ea_level0_row11\" class=\"row_heading level0 row11\" >dummy</th>\n", "      <td id=\"T_fe1ea_row11_col0\" class=\"data row11 col0\" >Dummy Classifier</td>\n", "      <td id=\"T_fe1ea_row11_col1\" class=\"data row11 col1\" >0.7592</td>\n", "      <td id=\"T_fe1ea_row11_col2\" class=\"data row11 col2\" >0.0000</td>\n", "      <td id=\"T_fe1ea_row11_col3\" class=\"data row11 col3\" >0.7592</td>\n", "      <td id=\"T_fe1ea_row11_col4\" class=\"data row11 col4\" >0.5763</td>\n", "      <td id=\"T_fe1ea_row11_col5\" class=\"data row11 col5\" >0.6552</td>\n", "      <td id=\"T_fe1ea_row11_col6\" class=\"data row11 col6\" >0.0000</td>\n", "      <td id=\"T_fe1ea_row11_col7\" class=\"data row11 col7\" >0.0000</td>\n", "      <td id=\"T_fe1ea_row11_col8\" class=\"data row11 col8\" >0.5420</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_fe1ea_level0_row12\" class=\"row_heading level0 row12\" >qda</th>\n", "      <td id=\"T_fe1ea_row12_col0\" class=\"data row12 col0\" >Quadratic Discriminant Analysis</td>\n", "      <td id=\"T_fe1ea_row12_col1\" class=\"data row12 col1\" >0.6271</td>\n", "      <td id=\"T_fe1ea_row12_col2\" class=\"data row12 col2\" >0.0000</td>\n", "      <td id=\"T_fe1ea_row12_col3\" class=\"data row12 col3\" >0.6271</td>\n", "      <td id=\"T_fe1ea_row12_col4\" class=\"data row12 col4\" >0.7707</td>\n", "      <td id=\"T_fe1ea_row12_col5\" class=\"data row12 col5\" >0.6530</td>\n", "      <td id=\"T_fe1ea_row12_col6\" class=\"data row12 col6\" >0.2646</td>\n", "      <td id=\"T_fe1ea_row12_col7\" class=\"data row12 col7\" >0.3138</td>\n", "      <td id=\"T_fe1ea_row12_col8\" class=\"data row12 col8\" >4.0840</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_fe1ea_level0_row13\" class=\"row_heading level0 row13\" >nb</th>\n", "      <td id=\"T_fe1ea_row13_col0\" class=\"data row13 col0\" >Naive Bayes</td>\n", "      <td id=\"T_fe1ea_row13_col1\" class=\"data row13 col1\" >0.5751</td>\n", "      <td id=\"T_fe1ea_row13_col2\" class=\"data row13 col2\" >0.0000</td>\n", "      <td id=\"T_fe1ea_row13_col3\" class=\"data row13 col3\" >0.5751</td>\n", "      <td id=\"T_fe1ea_row13_col4\" class=\"data row13 col4\" >0.8171</td>\n", "      <td id=\"T_fe1ea_row13_col5\" class=\"data row13 col5\" >0.5956</td>\n", "      <td id=\"T_fe1ea_row13_col6\" class=\"data row13 col6\" >0.2577</td>\n", "      <td id=\"T_fe1ea_row13_col7\" class=\"data row13 col7\" >0.3588</td>\n", "      <td id=\"T_fe1ea_row13_col8\" class=\"data row13 col8\" >0.8300</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n"], "text/plain": ["<pandas.io.formats.style.Styler at 0x13dbc9b10>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": [], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}], "source": "# Setup with GPU if available; fix imbalance and enable basic preprocessing\ns = setup(\n    data=df,\n    target='income',\n    session_id=42,\n    train_size=0.8,\n    fold=5,\n    normalize=True,\n    fix_imbalance=True,\n    use_gpu=False,\n    log_experiment=True,\n    experiment_name='pycaret_binary_adult',\n)\ncompare_models();"}, {"cell_type": "code", "execution_count": 3, "id": "7dcf9138", "metadata": {}, "outputs": [{"data": {"text/html": [], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": ["<style type=\"text/css\">\n", "#T_c0301 th {\n", "  text-align: left;\n", "}\n", "#T_c0301_row0_col0, #T_c0301_row1_col0, #T_c0301_row1_col1, #T_c0301_row1_col3, #T_c0301_row1_col4, #T_c0301_row1_col5, #T_c0301_row1_col6, #T_c0301_row1_col7, #T_c0301_row2_col0, #T_c0301_row2_col1, #T_c0301_row2_col3, #T_c0301_row2_col4, #T_c0301_row2_col5, #T_c0301_row2_col6, #T_c0301_row2_col7, #T_c0301_row3_col0, #T_c0301_row3_col1, #T_c0301_row3_col3, #T_c0301_row3_col4, #T_c0301_row3_col5, #T_c0301_row3_col6, #T_c0301_row3_col7, #T_c0301_row4_col0, #T_c0301_row4_col1, #T_c0301_row4_col3, #T_c0301_row4_col4, #T_c0301_row4_col5, #T_c0301_row4_col6, #T_c0301_row4_col7, #T_c0301_row5_col0, #T_c0301_row5_col1, #T_c0301_row5_col3, #T_c0301_row5_col4, #T_c0301_row5_col5, #T_c0301_row5_col6, #T_c0301_row5_col7, #T_c0301_row6_col0, #T_c0301_row6_col1, #T_c0301_row6_col3, #T_c0301_row6_col4, #T_c0301_row6_col5, #T_c0301_row6_col6, #T_c0301_row6_col7, #T_c0301_row7_col0, #T_c0301_row7_col1, #T_c0301_row7_col3, #T_c0301_row7_col4, #T_c0301_row7_col5, #T_c0301_row7_col6, #T_c0301_row7_col7, #T_c0301_row8_col0, #T_c0301_row8_col1, #T_c0301_row8_col3, #T_c0301_row8_col4, #T_c0301_row8_col5, #T_c0301_row8_col6, #T_c0301_row8_col7, #T_c0301_row9_col0, #T_c0301_row9_col1, #T_c0301_row9_col3, #T_c0301_row9_col4, #T_c0301_row9_col5, #T_c0301_row9_col6, #T_c0301_row9_col7, #T_c0301_row10_col0, #T_c0301_row10_col1, #T_c0301_row10_col3, #T_c0301_row10_col4, #T_c0301_row10_col5, #T_c0301_row10_col6, #T_c0301_row10_col7, #T_c0301_row11_col0, #T_c0301_row11_col1, #T_c0301_row11_col3, #T_c0301_row11_col4, #T_c0301_row11_col5, #T_c0301_row11_col6, #T_c0301_row11_col7, #T_c0301_row12_col0, #T_c0301_row12_col1, #T_c0301_row12_col3, #T_c0301_row12_col4, #T_c0301_row12_col5, #T_c0301_row12_col6, #T_c0301_row12_col7, #T_c0301_row13_col0, #T_c0301_row13_col1, #T_c0301_row13_col3, #T_c0301_row13_col4, #T_c0301_row13_col5, #T_c0301_row13_col6, #T_c0301_row13_col7 {\n", "  text-align: left;\n", "}\n", "#T_c0301_row0_col1, #T_c0301_row0_col2, #T_c0301_row0_col3, #T_c0301_row0_col4, #T_c0301_row0_col5, #T_c0301_row0_col6, #T_c0301_row0_col7, #T_c0301_row1_col2, #T_c0301_row2_col2, #T_c0301_row3_col2, #T_c0301_row4_col2, #T_c0301_row5_col2, #T_c0301_row6_col2, #T_c0301_row7_col2, #T_c0301_row8_col2, #T_c0301_row9_col2, #T_c0301_row10_col2, #T_c0301_row11_col2, #T_c0301_row12_col2, #T_c0301_row13_col2 {\n", "  text-align: left;\n", "  background-color: yellow;\n", "}\n", "#T_c0301_row0_col8, #T_c0301_row1_col8, #T_c0301_row2_col8, #T_c0301_row3_col8, #T_c0301_row4_col8, #T_c0301_row5_col8, #T_c0301_row6_col8, #T_c0301_row7_col8, #T_c0301_row8_col8, #T_c0301_row9_col8, #T_c0301_row10_col8, #T_c0301_row12_col8, #T_c0301_row13_col8 {\n", "  text-align: left;\n", "  background-color: lightgrey;\n", "}\n", "#T_c0301_row11_col8 {\n", "  text-align: left;\n", "  background-color: yellow;\n", "  background-color: lightgrey;\n", "}\n", "</style>\n", "<table id=\"T_c0301\">\n", "  <thead>\n", "    <tr>\n", "      <th class=\"blank level0\" >&nbsp;</th>\n", "      <th id=\"T_c0301_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n", "      <th id=\"T_c0301_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n", "      <th id=\"T_c0301_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n", "      <th id=\"T_c0301_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n", "      <th id=\"T_c0301_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n", "      <th id=\"T_c0301_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n", "      <th id=\"T_c0301_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n", "      <th id=\"T_c0301_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n", "      <th id=\"T_c0301_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th id=\"T_c0301_level0_row0\" class=\"row_heading level0 row0\" >lightgbm</th>\n", "      <td id=\"T_c0301_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n", "      <td id=\"T_c0301_row0_col1\" class=\"data row0 col1\" >0.8717</td>\n", "      <td id=\"T_c0301_row0_col2\" class=\"data row0 col2\" >0.0000</td>\n", "      <td id=\"T_c0301_row0_col3\" class=\"data row0 col3\" >0.8717</td>\n", "      <td id=\"T_c0301_row0_col4\" class=\"data row0 col4\" >0.8679</td>\n", "      <td id=\"T_c0301_row0_col5\" class=\"data row0 col5\" >0.8689</td>\n", "      <td id=\"T_c0301_row0_col6\" class=\"data row0 col6\" >0.6344</td>\n", "      <td id=\"T_c0301_row0_col7\" class=\"data row0 col7\" >0.6366</td>\n", "      <td id=\"T_c0301_row0_col8\" class=\"data row0 col8\" >3.6760</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_c0301_level0_row1\" class=\"row_heading level0 row1\" >gbc</th>\n", "      <td id=\"T_c0301_row1_col0\" class=\"data row1 col0\" >Gradient Boosting Classifier</td>\n", "      <td id=\"T_c0301_row1_col1\" class=\"data row1 col1\" >0.8606</td>\n", "      <td id=\"T_c0301_row1_col2\" class=\"data row1 col2\" >0.0000</td>\n", "      <td id=\"T_c0301_row1_col3\" class=\"data row1 col3\" >0.8606</td>\n", "      <td id=\"T_c0301_row1_col4\" class=\"data row1 col4\" >0.8580</td>\n", "      <td id=\"T_c0301_row1_col5\" class=\"data row1 col5\" >0.8590</td>\n", "      <td id=\"T_c0301_row1_col6\" class=\"data row1 col6\" >0.6102</td>\n", "      <td id=\"T_c0301_row1_col7\" class=\"data row1 col7\" >0.6109</td>\n", "      <td id=\"T_c0301_row1_col8\" class=\"data row1 col8\" >7.4640</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_c0301_level0_row2\" class=\"row_heading level0 row2\" >ada</th>\n", "      <td id=\"T_c0301_row2_col0\" class=\"data row2 col0\" >Ada Boost Classifier</td>\n", "      <td id=\"T_c0301_row2_col1\" class=\"data row2 col1\" >0.8528</td>\n", "      <td id=\"T_c0301_row2_col2\" class=\"data row2 col2\" >0.0000</td>\n", "      <td id=\"T_c0301_row2_col3\" class=\"data row2 col3\" >0.8528</td>\n", "      <td id=\"T_c0301_row2_col4\" class=\"data row2 col4\" >0.8524</td>\n", "      <td id=\"T_c0301_row2_col5\" class=\"data row2 col5\" >0.8526</td>\n", "      <td id=\"T_c0301_row2_col6\" class=\"data row2 col6\" >0.5961</td>\n", "      <td id=\"T_c0301_row2_col7\" class=\"data row2 col7\" >0.5962</td>\n", "      <td id=\"T_c0301_row2_col8\" class=\"data row2 col8\" >1.9500</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_c0301_level0_row3\" class=\"row_heading level0 row3\" >rf</th>\n", "      <td id=\"T_c0301_row3_col0\" class=\"data row3 col0\" >Random Forest Classifier</td>\n", "      <td id=\"T_c0301_row3_col1\" class=\"data row3 col1\" >0.8513</td>\n", "      <td id=\"T_c0301_row3_col2\" class=\"data row3 col2\" >0.0000</td>\n", "      <td id=\"T_c0301_row3_col3\" class=\"data row3 col3\" >0.8513</td>\n", "      <td id=\"T_c0301_row3_col4\" class=\"data row3 col4\" >0.8468</td>\n", "      <td id=\"T_c0301_row3_col5\" class=\"data row3 col5\" >0.8483</td>\n", "      <td id=\"T_c0301_row3_col6\" class=\"data row3 col6\" >0.5776</td>\n", "      <td id=\"T_c0301_row3_col7\" class=\"data row3 col7\" >0.5793</td>\n", "      <td id=\"T_c0301_row3_col8\" class=\"data row3 col8\" >1.7560</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_c0301_level0_row4\" class=\"row_heading level0 row4\" >et</th>\n", "      <td id=\"T_c0301_row4_col0\" class=\"data row4 col0\" >Extra Trees Classifier</td>\n", "      <td id=\"T_c0301_row4_col1\" class=\"data row4 col1\" >0.8350</td>\n", "      <td id=\"T_c0301_row4_col2\" class=\"data row4 col2\" >0.0000</td>\n", "      <td id=\"T_c0301_row4_col3\" class=\"data row4 col3\" >0.8350</td>\n", "      <td id=\"T_c0301_row4_col4\" class=\"data row4 col4\" >0.8314</td>\n", "      <td id=\"T_c0301_row4_col5\" class=\"data row4 col5\" >0.8328</td>\n", "      <td id=\"T_c0301_row4_col6\" class=\"data row4 col6\" >0.5372</td>\n", "      <td id=\"T_c0301_row4_col7\" class=\"data row4 col7\" >0.5380</td>\n", "      <td id=\"T_c0301_row4_col8\" class=\"data row4 col8\" >1.9360</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_c0301_level0_row5\" class=\"row_heading level0 row5\" >lr</th>\n", "      <td id=\"T_c0301_row5_col0\" class=\"data row5 col0\" >Logistic Regression</td>\n", "      <td id=\"T_c0301_row5_col1\" class=\"data row5 col1\" >0.8140</td>\n", "      <td id=\"T_c0301_row5_col2\" class=\"data row5 col2\" >0.0000</td>\n", "      <td id=\"T_c0301_row5_col3\" class=\"data row5 col3\" >0.8140</td>\n", "      <td id=\"T_c0301_row5_col4\" class=\"data row5 col4\" >0.8537</td>\n", "      <td id=\"T_c0301_row5_col5\" class=\"data row5 col5\" >0.8240</td>\n", "      <td id=\"T_c0301_row5_col6\" class=\"data row5 col6\" >0.5596</td>\n", "      <td id=\"T_c0301_row5_col7\" class=\"data row5 col7\" >0.5794</td>\n", "      <td id=\"T_c0301_row5_col8\" class=\"data row5 col8\" >1.8800</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_c0301_level0_row6\" class=\"row_heading level0 row6\" >dt</th>\n", "      <td id=\"T_c0301_row6_col0\" class=\"data row6 col0\" >Decision Tree Classifier</td>\n", "      <td id=\"T_c0301_row6_col1\" class=\"data row6 col1\" >0.8050</td>\n", "      <td id=\"T_c0301_row6_col2\" class=\"data row6 col2\" >0.0000</td>\n", "      <td id=\"T_c0301_row6_col3\" class=\"data row6 col3\" >0.8050</td>\n", "      <td id=\"T_c0301_row6_col4\" class=\"data row6 col4\" >0.8076</td>\n", "      <td id=\"T_c0301_row6_col5\" class=\"data row6 col5\" >0.8062</td>\n", "      <td id=\"T_c0301_row6_col6\" class=\"data row6 col6\" >0.4736</td>\n", "      <td id=\"T_c0301_row6_col7\" class=\"data row6 col7\" >0.4737</td>\n", "      <td id=\"T_c0301_row6_col8\" class=\"data row6 col8\" >0.9840</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_c0301_level0_row7\" class=\"row_heading level0 row7\" >knn</th>\n", "      <td id=\"T_c0301_row7_col0\" class=\"data row7 col0\" >K Neighbors Classifier</td>\n", "      <td id=\"T_c0301_row7_col1\" class=\"data row7 col1\" >0.8029</td>\n", "      <td id=\"T_c0301_row7_col2\" class=\"data row7 col2\" >0.0000</td>\n", "      <td id=\"T_c0301_row7_col3\" class=\"data row7 col3\" >0.8029</td>\n", "      <td id=\"T_c0301_row7_col4\" class=\"data row7 col4\" >0.8148</td>\n", "      <td id=\"T_c0301_row7_col5\" class=\"data row7 col5\" >0.8075</td>\n", "      <td id=\"T_c0301_row7_col6\" class=\"data row7 col6\" >0.4884</td>\n", "      <td id=\"T_c0301_row7_col7\" class=\"data row7 col7\" >0.4909</td>\n", "      <td id=\"T_c0301_row7_col8\" class=\"data row7 col8\" >1.7900</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_c0301_level0_row8\" class=\"row_heading level0 row8\" >svm</th>\n", "      <td id=\"T_c0301_row8_col0\" class=\"data row8 col0\" >SVM - Linear Kernel</td>\n", "      <td id=\"T_c0301_row8_col1\" class=\"data row8 col1\" >0.8010</td>\n", "      <td id=\"T_c0301_row8_col2\" class=\"data row8 col2\" >0.0000</td>\n", "      <td id=\"T_c0301_row8_col3\" class=\"data row8 col3\" >0.8010</td>\n", "      <td id=\"T_c0301_row8_col4\" class=\"data row8 col4\" >0.8474</td>\n", "      <td id=\"T_c0301_row8_col5\" class=\"data row8 col5\" >0.8124</td>\n", "      <td id=\"T_c0301_row8_col6\" class=\"data row8 col6\" >0.5358</td>\n", "      <td id=\"T_c0301_row8_col7\" class=\"data row8 col7\" >0.5587</td>\n", "      <td id=\"T_c0301_row8_col8\" class=\"data row8 col8\" >1.4380</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_c0301_level0_row9\" class=\"row_heading level0 row9\" >ridge</th>\n", "      <td id=\"T_c0301_row9_col0\" class=\"data row9 col0\" >Ridge Classifier</td>\n", "      <td id=\"T_c0301_row9_col1\" class=\"data row9 col1\" >0.7860</td>\n", "      <td id=\"T_c0301_row9_col2\" class=\"data row9 col2\" >0.0000</td>\n", "      <td id=\"T_c0301_row9_col3\" class=\"data row9 col3\" >0.7860</td>\n", "      <td id=\"T_c0301_row9_col4\" class=\"data row9 col4\" >0.8439</td>\n", "      <td id=\"T_c0301_row9_col5\" class=\"data row9 col5\" >0.7993</td>\n", "      <td id=\"T_c0301_row9_col6\" class=\"data row9 col6\" >0.5131</td>\n", "      <td id=\"T_c0301_row9_col7\" class=\"data row9 col7\" >0.5423</td>\n", "      <td id=\"T_c0301_row9_col8\" class=\"data row9 col8\" >0.9880</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_c0301_level0_row10\" class=\"row_heading level0 row10\" >lda</th>\n", "      <td id=\"T_c0301_row10_col0\" class=\"data row10 col0\" >Linear Discriminant Analysis</td>\n", "      <td id=\"T_c0301_row10_col1\" class=\"data row10 col1\" >0.7860</td>\n", "      <td id=\"T_c0301_row10_col2\" class=\"data row10 col2\" >0.0000</td>\n", "      <td id=\"T_c0301_row10_col3\" class=\"data row10 col3\" >0.7860</td>\n", "      <td id=\"T_c0301_row10_col4\" class=\"data row10 col4\" >0.8439</td>\n", "      <td id=\"T_c0301_row10_col5\" class=\"data row10 col5\" >0.7993</td>\n", "      <td id=\"T_c0301_row10_col6\" class=\"data row10 col6\" >0.5131</td>\n", "      <td id=\"T_c0301_row10_col7\" class=\"data row10 col7\" >0.5423</td>\n", "      <td id=\"T_c0301_row10_col8\" class=\"data row10 col8\" >1.7580</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_c0301_level0_row11\" class=\"row_heading level0 row11\" >dummy</th>\n", "      <td id=\"T_c0301_row11_col0\" class=\"data row11 col0\" >Dummy Classifier</td>\n", "      <td id=\"T_c0301_row11_col1\" class=\"data row11 col1\" >0.7592</td>\n", "      <td id=\"T_c0301_row11_col2\" class=\"data row11 col2\" >0.0000</td>\n", "      <td id=\"T_c0301_row11_col3\" class=\"data row11 col3\" >0.7592</td>\n", "      <td id=\"T_c0301_row11_col4\" class=\"data row11 col4\" >0.5763</td>\n", "      <td id=\"T_c0301_row11_col5\" class=\"data row11 col5\" >0.6552</td>\n", "      <td id=\"T_c0301_row11_col6\" class=\"data row11 col6\" >0.0000</td>\n", "      <td id=\"T_c0301_row11_col7\" class=\"data row11 col7\" >0.0000</td>\n", "      <td id=\"T_c0301_row11_col8\" class=\"data row11 col8\" >0.6500</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_c0301_level0_row12\" class=\"row_heading level0 row12\" >qda</th>\n", "      <td id=\"T_c0301_row12_col0\" class=\"data row12 col0\" >Quadratic Discriminant Analysis</td>\n", "      <td id=\"T_c0301_row12_col1\" class=\"data row12 col1\" >0.6271</td>\n", "      <td id=\"T_c0301_row12_col2\" class=\"data row12 col2\" >0.0000</td>\n", "      <td id=\"T_c0301_row12_col3\" class=\"data row12 col3\" >0.6271</td>\n", "      <td id=\"T_c0301_row12_col4\" class=\"data row12 col4\" >0.7707</td>\n", "      <td id=\"T_c0301_row12_col5\" class=\"data row12 col5\" >0.6530</td>\n", "      <td id=\"T_c0301_row12_col6\" class=\"data row12 col6\" >0.2646</td>\n", "      <td id=\"T_c0301_row12_col7\" class=\"data row12 col7\" >0.3138</td>\n", "      <td id=\"T_c0301_row12_col8\" class=\"data row12 col8\" >5.0820</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_c0301_level0_row13\" class=\"row_heading level0 row13\" >nb</th>\n", "      <td id=\"T_c0301_row13_col0\" class=\"data row13 col0\" >Naive Bayes</td>\n", "      <td id=\"T_c0301_row13_col1\" class=\"data row13 col1\" >0.5751</td>\n", "      <td id=\"T_c0301_row13_col2\" class=\"data row13 col2\" >0.0000</td>\n", "      <td id=\"T_c0301_row13_col3\" class=\"data row13 col3\" >0.5751</td>\n", "      <td id=\"T_c0301_row13_col4\" class=\"data row13 col4\" >0.8171</td>\n", "      <td id=\"T_c0301_row13_col5\" class=\"data row13 col5\" >0.5956</td>\n", "      <td id=\"T_c0301_row13_col6\" class=\"data row13 col6\" >0.2577</td>\n", "      <td id=\"T_c0301_row13_col7\" class=\"data row13 col7\" >0.3588</td>\n", "      <td id=\"T_c0301_row13_col8\" class=\"data row13 col8\" >0.7960</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n"], "text/plain": ["<pandas.io.formats.style.Styler at 0x141996b50>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": [], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": [], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": ["<style type=\"text/css\">\n", "#T_2d32f_row5_col0, #T_2d32f_row5_col1, #T_2d32f_row5_col2, #T_2d32f_row5_col3, #T_2d32f_row5_col4, #T_2d32f_row5_col5, #T_2d32f_row5_col6 {\n", "  background: yellow;\n", "}\n", "</style>\n", "<table id=\"T_2d32f\">\n", "  <thead>\n", "    <tr>\n", "      <th class=\"blank level0\" >&nbsp;</th>\n", "      <th id=\"T_2d32f_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n", "      <th id=\"T_2d32f_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n", "      <th id=\"T_2d32f_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n", "      <th id=\"T_2d32f_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n", "      <th id=\"T_2d32f_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n", "      <th id=\"T_2d32f_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n", "      <th id=\"T_2d32f_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n", "    </tr>\n", "    <tr>\n", "      <th class=\"index_name level0\" >Fold</th>\n", "      <th class=\"blank col0\" >&nbsp;</th>\n", "      <th class=\"blank col1\" >&nbsp;</th>\n", "      <th class=\"blank col2\" >&nbsp;</th>\n", "      <th class=\"blank col3\" >&nbsp;</th>\n", "      <th class=\"blank col4\" >&nbsp;</th>\n", "      <th class=\"blank col5\" >&nbsp;</th>\n", "      <th class=\"blank col6\" >&nbsp;</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th id=\"T_2d32f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n", "      <td id=\"T_2d32f_row0_col0\" class=\"data row0 col0\" >0.8747</td>\n", "      <td id=\"T_2d32f_row0_col1\" class=\"data row0 col1\" >0.0000</td>\n", "      <td id=\"T_2d32f_row0_col2\" class=\"data row0 col2\" >0.8747</td>\n", "      <td id=\"T_2d32f_row0_col3\" class=\"data row0 col3\" >0.8709</td>\n", "      <td id=\"T_2d32f_row0_col4\" class=\"data row0 col4\" >0.8718</td>\n", "      <td id=\"T_2d32f_row0_col5\" class=\"data row0 col5\" >0.6426</td>\n", "      <td id=\"T_2d32f_row0_col6\" class=\"data row0 col6\" >0.6448</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_2d32f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n", "      <td id=\"T_2d32f_row1_col0\" class=\"data row1 col0\" >0.8689</td>\n", "      <td id=\"T_2d32f_row1_col1\" class=\"data row1 col1\" >0.0000</td>\n", "      <td id=\"T_2d32f_row1_col2\" class=\"data row1 col2\" >0.8689</td>\n", "      <td id=\"T_2d32f_row1_col3\" class=\"data row1 col3\" >0.8651</td>\n", "      <td id=\"T_2d32f_row1_col4\" class=\"data row1 col4\" >0.8662</td>\n", "      <td id=\"T_2d32f_row1_col5\" class=\"data row1 col5\" >0.6275</td>\n", "      <td id=\"T_2d32f_row1_col6\" class=\"data row1 col6\" >0.6293</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_2d32f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n", "      <td id=\"T_2d32f_row2_col0\" class=\"data row2 col0\" >0.8701</td>\n", "      <td id=\"T_2d32f_row2_col1\" class=\"data row2 col1\" >0.0000</td>\n", "      <td id=\"T_2d32f_row2_col2\" class=\"data row2 col2\" >0.8701</td>\n", "      <td id=\"T_2d32f_row2_col3\" class=\"data row2 col3\" >0.8657</td>\n", "      <td id=\"T_2d32f_row2_col4\" class=\"data row2 col4\" >0.8666</td>\n", "      <td id=\"T_2d32f_row2_col5\" class=\"data row2 col5\" >0.6269</td>\n", "      <td id=\"T_2d32f_row2_col6\" class=\"data row2 col6\" >0.6299</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_2d32f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n", "      <td id=\"T_2d32f_row3_col0\" class=\"data row3 col0\" >0.8647</td>\n", "      <td id=\"T_2d32f_row3_col1\" class=\"data row3 col1\" >0.0000</td>\n", "      <td id=\"T_2d32f_row3_col2\" class=\"data row3 col2\" >0.8647</td>\n", "      <td id=\"T_2d32f_row3_col3\" class=\"data row3 col3\" >0.8603</td>\n", "      <td id=\"T_2d32f_row3_col4\" class=\"data row3 col4\" >0.8614</td>\n", "      <td id=\"T_2d32f_row3_col5\" class=\"data row3 col5\" >0.6130</td>\n", "      <td id=\"T_2d32f_row3_col6\" class=\"data row3 col6\" >0.6154</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_2d32f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n", "      <td id=\"T_2d32f_row4_col0\" class=\"data row4 col0\" >0.8712</td>\n", "      <td id=\"T_2d32f_row4_col1\" class=\"data row4 col1\" >0.0000</td>\n", "      <td id=\"T_2d32f_row4_col2\" class=\"data row4 col2\" >0.8712</td>\n", "      <td id=\"T_2d32f_row4_col3\" class=\"data row4 col3\" >0.8679</td>\n", "      <td id=\"T_2d32f_row4_col4\" class=\"data row4 col4\" >0.8690</td>\n", "      <td id=\"T_2d32f_row4_col5\" class=\"data row4 col5\" >0.6360</td>\n", "      <td id=\"T_2d32f_row4_col6\" class=\"data row4 col6\" >0.6373</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_2d32f_level0_row5\" class=\"row_heading level0 row5\" >Mean</th>\n", "      <td id=\"T_2d32f_row5_col0\" class=\"data row5 col0\" >0.8699</td>\n", "      <td id=\"T_2d32f_row5_col1\" class=\"data row5 col1\" >0.0000</td>\n", "      <td id=\"T_2d32f_row5_col2\" class=\"data row5 col2\" >0.8699</td>\n", "      <td id=\"T_2d32f_row5_col3\" class=\"data row5 col3\" >0.8660</td>\n", "      <td id=\"T_2d32f_row5_col4\" class=\"data row5 col4\" >0.8670</td>\n", "      <td id=\"T_2d32f_row5_col5\" class=\"data row5 col5\" >0.6292</td>\n", "      <td id=\"T_2d32f_row5_col6\" class=\"data row5 col6\" >0.6313</td>\n", "    </tr>\n", "    <tr>\n", "      <th id=\"T_2d32f_level0_row6\" class=\"row_heading level0 row6\" >Std</th>\n", "      <td id=\"T_2d32f_row6_col0\" class=\"data row6 col0\" >0.0033</td>\n", "      <td id=\"T_2d32f_row6_col1\" class=\"data row6 col1\" >0.0000</td>\n", "      <td id=\"T_2d32f_row6_col2\" class=\"data row6 col2\" >0.0033</td>\n", "      <td id=\"T_2d32f_row6_col3\" class=\"data row6 col3\" >0.0035</td>\n", "      <td id=\"T_2d32f_row6_col4\" class=\"data row6 col4\" >0.0034</td>\n", "      <td id=\"T_2d32f_row6_col5\" class=\"data row6 col5\" >0.0100</td>\n", "      <td id=\"T_2d32f_row6_col6\" class=\"data row6 col6\" >0.0098</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n"], "text/plain": ["<pandas.io.formats.style.Styler at 0x13e65ab50>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": [], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": ["Fitting 5 folds for each of 10 candidates, totalling 50 fits\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.121024 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 11936\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061429 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Info] Total Bins 11957\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 63\n", "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.100454 seconds.\n", "You can set `force_col_wise=true` to remove the overhead.\n", "[LightGBM] [Info] Total Bins 12096\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 63\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030154 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12088\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099597 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12084\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 63\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088017 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12069\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014872 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12078\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008846 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12257\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012151 seconds.\n", "You can set `force_col_wise=true` to remove the overhead.\n", "[LightGBM] [Info] Total Bins 12267\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 63\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015991 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12106\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 63\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014548 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12069\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011144 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 11936\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019788 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12078\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037380 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12257\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n", "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.115691 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12088\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009153 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12084\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 63\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023213 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 11957\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 63\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n", "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n", "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036348 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12099\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 64\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n", "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n", "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024191 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12267\n", "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 63\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043298 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12106\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 63\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n", "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n", "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n", "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n", "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n", "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033743 seconds.\n", "You can set `force_col_wise=true` to remove the overhead.\n", "[LightGBM] [Info] Total Bins 12069\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n", "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n", "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n", "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n", "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n", "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n", "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n", "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n", "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.095295 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 11936\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n", "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n", "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052115 seconds.\n", "You can set `force_col_wise=true` to remove the overhead.\n", "[LightGBM] [Info] Total Bins 12078\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n", "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n", "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n", "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n", "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n", "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008512 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12257\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n", "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n", "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n", "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n", "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n", "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010237 seconds.\n", "You can set `force_col_wise=true` to remove the overhead.\n", "[LightGBM] [Info] Total Bins 12085\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 60\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n", "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n", "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n", "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n", "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n", "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n", "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n", "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047391 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12065\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 60\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n", "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n", "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010801 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12074\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 60\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034846 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 11932\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 60\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013788 seconds.\n", "You can set `force_col_wise=true` to remove the overhead.\n", "[LightGBM] [Info] Total Bins 12253\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 60\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015570 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12085\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 60\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n", "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n", "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010280 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12069\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049536 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 11936\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n", "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021484 seconds.\n", "You can set `force_col_wise=true` to remove the overhead.\n", "[LightGBM] [Info] Total Bins 12078\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068236 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12257\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074972 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12088\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.299552 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12069\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020958 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12078\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.311206 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 11936\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.135628 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12257\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043147 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12069\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083795 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12088\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066032 seconds.\n", "You can set `force_col_wise=true` to remove the overhead.\n", "[LightGBM] [Info] Total Bins 11936\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007838 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12078\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027896 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12257\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 61\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059929 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12085\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 60\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n", "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017562 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12090\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 65\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016655 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12270\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 64\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073523 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 11960\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 64\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Info] Number of positive: 15820, number of negative: 15820\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086431 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12099\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 64\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.169499 seconds.\n", "You can set `force_row_wise=true` to remove the overhead.\n", "And if memory is not enough, you can set `force_col_wise=true`.\n", "[LightGBM] [Info] Total Bins 12109\n", "[LightGBM] [Info] Number of data points in the train set: 31640, number of used features: 64\n", "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n", "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n", "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n", "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n", "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n", "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n"]}, {"data": {"text/html": [], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": [], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": [], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/plain": ["'Confusion Matrix.png'"]}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": ["best = compare_models(n_select=1)\n", "tuned = tune_model(best)\n", "plot_model(tuned, plot='auc', save=True)\n", "plot_model(tuned, plot='pr', save=True)\n", "plot_model(tuned, plot='confusion_matrix', save=True)"]}, {"cell_type": "code", "execution_count": 4, "id": "8defb719", "metadata": {}, "outputs": [{"data": {"text/html": ["<style type=\"text/css\">\n", "</style>\n", "<table id=\"T_00114\">\n", "  <thead>\n", "    <tr>\n", "      <th class=\"blank level0\" >&nbsp;</th>\n", "      <th id=\"T_00114_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n", "      <th id=\"T_00114_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n", "      <th id=\"T_00114_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n", "      <th id=\"T_00114_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n", "      <th id=\"T_00114_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n", "      <th id=\"T_00114_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n", "      <th id=\"T_00114_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n", "      <th id=\"T_00114_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th id=\"T_00114_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n", "      <td id=\"T_00114_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n", "      <td id=\"T_00114_row0_col1\" class=\"data row0 col1\" >0.3564</td>\n", "      <td id=\"T_00114_row0_col2\" class=\"data row0 col2\" >0.8698</td>\n", "      <td id=\"T_00114_row0_col3\" class=\"data row0 col3\" >0.3564</td>\n", "      <td id=\"T_00114_row0_col4\" class=\"data row0 col4\" >0.8238</td>\n", "      <td id=\"T_00114_row0_col5\" class=\"data row0 col5\" >0.3039</td>\n", "      <td id=\"T_00114_row0_col6\" class=\"data row0 col6\" >0.0794</td>\n", "      <td id=\"T_00114_row0_col7\" class=\"data row0 col7\" >0.2028</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n"], "text/plain": ["<pandas.io.formats.style.Styler at 0x153d35bd0>"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": ["       age         workclass  fnlwgt  education  education.num  \\\n", "10489   28  Self-emp-not-inc  204984  Bachelors             13   \n", "25652   19           Private  118306    HS-grad              9   \n", "12243   47           Private  212120  Bachelors             13   \n", "25487   54         State-gov  137065  Doctorate             16   \n", "5091    47           Private  335973    HS-grad              9   \n", "\n", "           marital.status         occupation   relationship   race     sex  \\\n", "10489       Never-married       Tech-support  Not-in-family  White    Male   \n", "25652       Never-married  Handlers-cleaners      Own-child  White    Male   \n", "12243  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n", "25487       Never-married    Exec-managerial  Not-in-family  White  Female   \n", "5091             Divorced       Adm-clerical      Unmarried  White  Female   \n", "\n", "       capital.gain  capital.loss  hours.per.week native.country income  \\\n", "10489             0             0              45  United-States  <=50K   \n", "25652             0             0              16  United-States  <=50K   \n", "12243             0             0              45  United-States   >50K   \n", "25487             0             0              40  United-States   >50K   \n", "5091              0             0              40  United-States  <=50K   \n", "\n", "      prediction_label  prediction_score  \n", "10489             >50K            0.9910  \n", "25652            <=50K            0.9512  \n", "12243             >50K            0.9976  \n", "25487             >50K            0.9890  \n", "5091              >50K            0.9346  \n", "Transformation Pipeline and Model Successfully Saved\n"]}, {"data": {"text/plain": ["(Pipeline(memory=Memory(location=None),\n", "          steps=[('label_encoding',\n", "                  TransformerWrapperWithInverse(exclude=None, include=None,\n", "                                                transformer=LabelEncoder())),\n", "                 ('numerical_imputer',\n", "                  TransformerWrapper(exclude=None,\n", "                                     include=['age', 'fnlwgt', 'education.num',\n", "                                              'capital.gain', 'capital.loss',\n", "                                              'hours.per.week'],\n", "                                     transformer=SimpleImputer(add_indicator=False,\n", "                                                               copy=True,\n", "                                                               fill_...\n", "                  LGBMClassifier(boosting_type='gbdt', class_weight=None,\n", "                                 colsample_bytree=1.0, importance_type='split',\n", "                                 learning_rate=0.1, max_depth=-1,\n", "                                 min_child_samples=20, min_child_weight=0.001,\n", "                                 min_split_gain=0.0, n_estimators=100, n_jobs=-1,\n", "                                 num_leaves=31, objective=None, random_state=42,\n", "                                 reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,\n", "                                 subsample_for_bin=200000, subsample_freq=0))],\n", "          verbose=False),\n", " 'binary_income_model.pkl')"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["final_best = finalize_model(tuned)\n", "preds = predict_model(final_best)\n", "print(preds.head())\n", "# Save model for reuse (e.g., Gradio demo)\n", "save_model(final_best, 'binary_income_model')"]}], "metadata": {"kernelspec": {"display_name": ".venv", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.14"}}, "nbformat": 4, "nbformat_minor": 5}