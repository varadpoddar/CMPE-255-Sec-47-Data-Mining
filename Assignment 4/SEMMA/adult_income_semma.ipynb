{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 â€” SEMMA Case Study (Adult Income Classification)\n",
    "\n",
    "Dataset: [`scikit-learn/adult-census-income`](https://huggingface.co/datasets/scikit-learn/adult-census-income)\n",
    "\n",
    "Goal: Predict income (<=50K vs >50K) using SEMMA: Sample, Explore, Modify, Model, Assess.\n",
    "\n",
    "Environment: Python 3.11 (`.venv`), scikit-learn, imbalanced-learn, pandas, seaborn, SHAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
    ")\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "import shap\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "FIG_DIR = Path(\"figures\")\n",
    "FIG_DIR.mkdir(exist_ok=True)\n",
    "RNG = 42\n",
    "pd.set_option(\"display.max_columns\", 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample\n",
    "- Load dataset from Hugging Face\n",
    "- Stratified split train/valid/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"scikit-learn/adult-census-income\", split=\"train\")\n",
    "df = ds.to_pandas()\n",
    "df.shape, df[\"income\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"income\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target].apply(lambda v: 1 if v.strip() == \">50K\" else 0)\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RNG\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, stratify=y_train_full, random_state=RNG\n",
    ")\n",
    "(X_train.shape, X_valid.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore\n",
    "- Missingness, target balance\n",
    "- Univariate distributions (numeric)\n",
    "- Categorical frequency\n",
    "- Correlations (numeric) and target relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "missing.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=[\"object\", \"string\"]).columns.tolist()\n",
    "\n",
    "fig, axes = plt.subplots(2, len(numeric_cols)//2, figsize=(14, 6))\n",
    "axes = axes.flatten()\n",
    "for ax, col in zip(axes, numeric_cols):\n",
    "    sns.histplot(df[col], kde=True, ax=ax)\n",
    "    ax.set_title(col)\n",
    "plt.tight_layout()\nunivar_num_fig = FIG_DIR / \"univar_numeric.png\"\n",
    "plt.savefig(univar_num_fig)\nunivar_num_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "freq = df[target].value_counts(normalize=True) * 100\n",
    "sns.barplot(x=freq.index, y=freq.values)\n",
    "plt.title(\"Target balance (% >50K vs <=50K)\")\n",
    "plt.tight_layout()\nbalance_fig = FIG_DIR / \"target_balance.png\"\n",
    "plt.savefig(balance_fig)\nbalance_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df[numeric_cols + [target]].assign(income=y).corr()[\"income\"].drop(\"income\")\n",
    "top_corr = corr.abs().sort_values(ascending=False).head(10).index\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(df[list(top_corr) + [target]].assign(income=y).corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation with income (top numeric)\")\n",
    "plt.tight_layout()\ncorr_fig = FIG_DIR / \"corr_top_numeric.png\"\n",
    "plt.savefig(corr_fig)\ncorr_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify\n",
    "- Impute + one-hot; scale numerics for linear models\n",
    "- Compare class_weight vs SMOTE for imbalance\n",
    "- Simple feature tweaks: bin age, combine rare categories if needed (skipped here for brevity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"most_frequent\")), (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_cols),\n",
    "    (\"cat\", categorical_transformer, categorical_cols),\n",
    "])\n",
    "\n",
    "def evaluate_clf(pipe, Xtr, ytr, Xval, yval, name: str):\n",
    "    pipe.fit(Xtr, ytr)\n",
    "    proba = pipe.predict_proba(Xval)[:, 1]\n",
    "    preds = (proba >= 0.5).astype(int)\n",
    "    roc = roc_auc_score(yval, proba)\n",
    "    pr = average_precision_score(yval, proba)\n",
    "    return {\"name\": name, \"roc_auc\": roc, \"avg_precision\": pr, \"pipeline\": pipe}\n",
    "\n",
    "results = []\n",
    "results.append(evaluate_clf(\n",
    "    Pipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"model\", DummyClassifier(strategy=\"most_frequent\"))\n",
    "    ]),\n",
    "    X_train, y_train, X_valid, y_valid, \"Dummy\")\n",
    ")\n",
    "\n",
    "results.append(evaluate_clf(\n",
    "    Pipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"model\", LogisticRegression(max_iter=1000, class_weight=\"balanced\"))\n",
    "    ]),\n",
    "    X_train, y_train, X_valid, y_valid, \"LogReg (balanced)\")\n",
    ")\n",
    "\n",
    "results.append(evaluate_clf(\n",
    "    ImbPipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"smote\", SMOTE(random_state=RNG)),\n",
    "        (\"model\", LogisticRegression(max_iter=1000))\n",
    "    ]),\n",
    "    X_train, y_train, X_valid, y_valid, \"LogReg + SMOTE\")\n",
    ")\n",
    "\n",
    "results.append(evaluate_clf(\n",
    "    Pipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"model\", GradientBoostingClassifier(random_state=RNG))\n",
    "    ]),\n",
    "    X_train, y_train, X_valid, y_valid, \"GradientBoosting\")\n",
    ")\n",
    "\n",
    "pd.DataFrame([{k: v for k, v in r.items() if k != \"pipeline\"} for r in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick best by ROC-AUC\n",
    "best = sorted(results, key=lambda d: d[\"roc_auc\"], reverse=True)[0]\n",
    "best_name = best[\"name\"]\n",
    "best_pipe = best[\"pipeline\"]\n",
    "best_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning on GradientBoosting\n",
    "param_dist = {\n",
    "    \"model__n_estimators\": [150, 200, 300],\n",
    "    \"model__learning_rate\": [0.05, 0.075, 0.1],\n",
    "    \"model__max_depth\": [2, 3, 4],\n",
    "}\n",
    "search = RandomizedSearchCV(\n",
    "    Pipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"model\", GradientBoostingClassifier(random_state=RNG))\n",
    "    ]),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=8,\n",
    "    cv=3,\n",
    "    scoring=\"roc_auc\",\n",
    "    random_state=RNG,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "search.fit(X_train, y_train)\n",
    "{'best_params': search.best_params_, 'best_cv_roc_auc': search.best_score_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit tuned model on train+valid, evaluate on test\n",
    "tuned_pipe = search.best_estimator_\n",
    "tuned_pipe.fit(pd.concat([X_train, X_valid]), pd.concat([y_train, y_valid]))\n",
    "\n",
    "proba_test = tuned_pipe.predict_proba(X_test)[:,1]\n",
    "preds_test = (proba_test >= 0.5).astype(int)\n",
    "roc_test = roc_auc_score(y_test, proba_test)\n",
    "pr_test = average_precision_score(y_test, proba_test)\n",
    "cm = confusion_matrix(y_test, preds_test)\n",
    "\n",
    "report = classification_report(y_test, preds_test, target_names=[\"<=50K\", \">50K\"], output_dict=True)\n",
    "roc_test, pr_test, cm, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and PR curves\n",
    "fpr, tpr, _ = roc_curve(y_test, proba_test)\n",
    "prec, rec, _ = precision_recall_curve(y_test, proba_test)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "ax[0].plot(fpr, tpr, label=f\"ROC-AUC={roc_test:.3f}\")\n",
    "ax[0].plot([0,1],[0,1],'--', color='gray')\n",
    "ax[0].set_title(\"ROC\")\n",
    "ax[0].set_xlabel(\"FPR\")\n",
    "ax[0].set_ylabel(\"TPR\")\n",
    "\n",
    "ax[1].plot(rec, prec, label=f\"PR-AUC={pr_test:.3f}\")\n",
    "ax[1].set_title(\"Precision-Recall\")\n",
    "ax[1].set_xlabel(\"Recall\")\n",
    "ax[1].set_ylabel(\"Precision\")\n",
    "plt.tight_layout()\n",
    "curves_fig = FIG_DIR / \"roc_pr_curves.png\"\n",
    "plt.savefig(curves_fig)\n",
    "curves_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=[\"<=50K\", \">50K\"])\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix (test)\")\n",
    "cm_fig = FIG_DIR / \"confusion_matrix.png\"\n",
    "plt.savefig(cm_fig)\n",
    "cm_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP summary (on a sample for speed)\n",
    "X_sample = X_test.sample(n=min(400, len(X_test)), random_state=RNG)\n",
    "X_proc = tuned_pipe.named_steps[\"prep\"].transform(X_sample)\n",
    "if hasattr(X_proc, \"toarray\"):\n",
    "    X_proc = X_proc.toarray()\n",
    "feature_names = tuned_pipe.named_steps[\"prep\"].get_feature_names_out()\n",
    "explainer = shap.Explainer(tuned_pipe.named_steps[\"model\"], X_proc, feature_names=feature_names)\n",
    "shap_values = explainer(X_proc)\n",
    "shap.plots.beeswarm(shap_values, max_display=15, show=False)\n",
    "plt.tight_layout()\n",
    "shap_fig = FIG_DIR / \"shap_beeswarm.png\"\n",
    "plt.savefig(shap_fig, bbox_inches=\"tight\")\n",
    "shap_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice metrics (by sex and marital.status)\n",
    "slice_cols = [\"sex\", \"marital.status\"]\n",
    "slice_metrics = []\n",
    "df_test = X_test.copy()\n",
    "df_test[\"y\"] = y_test.values\n",
    "df_test[\"proba\"] = proba_test\n",
    "df_test[\"pred\"] = preds_test\n",
    "for col in slice_cols:\n",
    "    for level, grp in df_test.groupby(col):\n",
    "        roc = roc_auc_score(grp[\"y\"], grp[\"proba\"]) if grp[\"y\"].nunique()>1 else np.nan\n",
    "        pr = average_precision_score(grp[\"y\"], grp[\"proba\"]) if grp[\"y\"].nunique()>1 else np.nan\n",
    "        slice_metrics.append({\"slice\": f\"{col}={level}\", \"roc_auc\": roc, \"avg_precision\": pr, \"n\": len(grp)})\n",
    "pd.DataFrame(slice_metrics).sort_values(\"roc_auc\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess (summary)\n",
    "- Best model: tuned GradientBoostingClassifier with one-hot + scaling, evaluated on test.\n",
    "- Report: see classification_report, ROC/PR curves, confusion matrix, slices, and SHAP.\n",
    "- Deployment: bundle preprocess + model, monitor slice metrics and calibration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
