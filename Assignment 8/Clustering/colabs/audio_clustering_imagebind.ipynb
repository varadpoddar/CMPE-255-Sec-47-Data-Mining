{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d669aa6b",
   "metadata": {},
   "source": [
    "# Audio Clustering with ImageBind Embeddings\n",
    "Template: extract audio embeddings via ImageBind and cluster. Run in Colab with GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc1e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install\n",
    "!pip install -q git+https://github.com/facebookresearch/ImageBind.git scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9231c897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from imagebind.models import imagebind_model\n",
    "from imagebind.models.imagebind_model import ModalityType\n",
    "from imagebind.data import load_and_transform_audio_data\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Sample audio URLs (replace with your own short clips)\n",
    "audio_urls = [\n",
    "    'https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac',\n",
    "    'https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/2.flac',\n",
    "    'https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/3.flac',\n",
    "]\n",
    "audio_data = load_and_transform_audio_data(audio_urls, device='cpu')\n",
    "model = imagebind_model.imagebind_huge(pretrained=True)\n",
    "with torch.no_grad():\n",
    "    embeddings = model({ModalityType.AUDIO: audio_data})[ModalityType.AUDIO].cpu().numpy()\n",
    "km = KMeans(n_clusters=3, random_state=42, n_init='auto').fit(embeddings)\n",
    "print('Cluster labels:', km.labels_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c340c99",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- Use short audio clips; GPU strongly recommended.\n",
    "- Optionally run PCA/TSNE on embeddings to visualize."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
